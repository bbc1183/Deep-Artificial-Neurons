{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txzx1mIG71YF"
      },
      "source": [
        "Let's generate and plot a sample function just to visualize the type of function we wish to model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1ChTnoABWRY"
      },
      "source": [
        "LET'S MAKE A NETWORK OF DANS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "Wlha_c5yBVox",
        "outputId": "efc11197-0f83-40f9-facd-8c57ba7a3d99"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "# from google.colab import drive \n",
        "# drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3EgppR10Cbe-"
      },
      "outputs": [],
      "source": [
        "args = {}\n",
        "args['n_channels'] = 20\n",
        "args['dims'] = [1, 5, 10, 5, 1]\n",
        "args['local_path'] = './HLIR_NB_DATA/'\n",
        "args['dan_width'] = 70"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ocymhDyJByOf"
      },
      "outputs": [],
      "source": [
        "import copy \n",
        "class SIMPLE_DAN(nn.Module):\n",
        "    # DIMS ARE [n_channels, 50, 100, 50, 1]\n",
        "    # idx      [         0,  1,   2,  3, 4]\n",
        "    def __init__(self, n_channels, args):\n",
        "        super(SIMPLE_DAN, self).__init__()\n",
        "        self.hidden_dim = args['dan_width']\n",
        "        self.fc0 = nn.Linear(n_channels, self.hidden_dim)\n",
        "        self.fc1 = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "        self.fc2 = nn.Linear(self.hidden_dim, self.hidden_dim) \n",
        "        self.fc3 = nn.Linear(self.hidden_dim, 1) \n",
        "        self.SKIPS = nn.ModuleDict() \n",
        "\n",
        "        self.SKIPS['skip 0-2'] = nn.Linear(n_channels,self.hidden_dim)\n",
        "        self.SKIPS['skip 0-3'] = nn.Linear(n_channels,self.hidden_dim)\n",
        "        self.SKIPS['skip 0-4'] = nn.Linear(n_channels, 1)\n",
        "\n",
        "        self.SKIPS['skip 1-3'] = nn.Linear(self.hidden_dim, self.hidden_dim)\n",
        "        self.SKIPS['skip 1-4'] = nn.Linear(self.hidden_dim, 1)\n",
        "        \n",
        "        self.SKIPS['skip 2-4'] = nn.Linear(self.hidden_dim, 1)\n",
        "    \n",
        "    def forward(self, x, width): \n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        x_0_2 = self.SKIPS['skip 0-2'](x.clone())\n",
        "        x_0_3 = self.SKIPS['skip 0-3'](x.clone())\n",
        "        x_0_4 = self.SKIPS['skip 0-4'](x.clone())\n",
        "        x1 = F.tanh(self.fc0(x.clone()))\n",
        "        \n",
        "        x_1_3 = self.SKIPS['skip 1-3'](x1.clone())\n",
        "        x_1_4 = self.SKIPS['skip 1-4'](x1.clone())\n",
        "        x2 = self.fc1(x1.clone())\n",
        "        x2 = F.tanh(x2 + x_0_2)\n",
        "        \n",
        "        x_2_4 = self.SKIPS['skip 2-4'](x2.clone())\n",
        "        x3 = self.fc2(x2.clone())\n",
        "        x3 = F.tanh(x3 + x_0_3 + x_1_3)\n",
        "        \n",
        "        x4 = self.fc3(x3.clone())\n",
        "        x4 = F.tanh(x4 + x_0_4 + x_1_4 + x_2_4)\n",
        "\n",
        "        x4 = x4.view((len(torch.flatten(x4))//width, width))\n",
        "        return x4\n",
        "\n",
        "\n",
        "class NET(nn.Module):\n",
        "    #  DIMS ARE [1, 50, 100, 50, 1]\n",
        "    #  idx      [0,  1,   2,  3, 4]\n",
        "    #  Total params: 193,506\n",
        "    def __init__(self, n_channels, dims, args=None):\n",
        "        super(NET, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "        self.VECS = nn.ModuleDict() \n",
        "        self.DANS = nn.ModuleDict() \n",
        "        self.VECS['fc0'] = nn.Linear(dims[0], dims[1]*n_channels)\n",
        "        self.VECS['fc1'] = nn.Linear(dims[1], dims[2]*n_channels)\n",
        "        self.VECS['fc2'] = nn.Linear(dims[2], dims[3]*n_channels)  \n",
        "        self.VECS['fc3'] = nn.Linear(dims[3], dims[4]*n_channels) \n",
        "\n",
        "        # self.VECS['fc0_norm'] = nn.LayerNorm(dims[1]*n_channels)\n",
        "        # self.VECS['fc1_norm'] = nn.LayerNorm(dims[2]*n_channels)\n",
        "        # self.VECS['fc2_norm'] = nn.LayerNorm(dims[3]*n_channels)\n",
        "        # self.VECS['fc3_norm'] = nn.LayerNorm(dims[4]*n_channels)\n",
        "\n",
        "        self.DANS['L1'] = SIMPLE_DAN(n_channels, args)\n",
        "        # self.DANS['L2'] = SIMPLE_DAN(n_channels)\n",
        "        # self.DANS['L3'] = SIMPLE_DAN(n_channels)\n",
        "        # self.DANS['L4'] = SIMPLE_DAN(n_channels)\n",
        "\n",
        "        self.VECS['skip 0-2'] = nn.Linear(dims[0], dims[2]*n_channels)\n",
        "        self.VECS['skip 0-3'] = nn.Linear(dims[0], dims[3]*n_channels)\n",
        "        self.VECS['skip 0-4'] = nn.Linear(dims[0], dims[4]*n_channels)\n",
        "\n",
        "        self.VECS['skip 1-3'] = nn.Linear(dims[1], dims[3]*n_channels)\n",
        "        self.VECS['skip 1-4'] = nn.Linear(dims[1], dims[4]*n_channels)\n",
        "        \n",
        "        self.VECS['skip 2-4'] = nn.Linear(dims[2], dims[4]*n_channels)\n",
        "\n",
        "        torch.nn.init.xavier_uniform_(self.VECS['fc0'].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.VECS['fc1'].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.VECS['fc2'].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.VECS['fc3'].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.VECS['skip 0-2'].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.VECS['skip 0-3'].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.VECS['skip 0-4'].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.VECS['skip 1-3'].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.VECS['skip 1-4'].weight)\n",
        "        torch.nn.init.xavier_uniform_(self.VECS['skip 2-4'].weight)\n",
        "\n",
        "        self.init_VECS = copy.deepcopy(self.VECS.state_dict())\n",
        "\n",
        "    def get_DAN_size(self):\n",
        "        total = 0\n",
        "        for p in self.DANS['L1'].parameters():\n",
        "          total += torch.flatten(p).shape[0]\n",
        "        return total  \n",
        "\n",
        "    def get_plasticity_ratio(self):\n",
        "        return round((self.get_model_size()-self.get_DAN_size())/self.get_model_size(), 2)\n",
        "\n",
        "    def get_model_size(self):\n",
        "        total = 0\n",
        "        for p in self.parameters():\n",
        "          total += torch.flatten(p).shape[0]\n",
        "        return total \n",
        "\n",
        "    def reset_VECS(self, vecs_lr, avg_vecs = None):\n",
        "        if avg_vecs:\n",
        "            self.init_VECS = avg_vecs\n",
        "        self.VECS.load_state_dict(self.init_VECS)\n",
        "        return torch.optim.Adam(self.VECS.parameters(),  lr=vecs_lr)\n",
        "    \n",
        "\n",
        "    def forward(self, x, args): \n",
        "        batch_size = args['B']\n",
        "        num_samples = args['N']\n",
        "        \n",
        "        \n",
        "        \n",
        "\n",
        "        x_0_2 = self.VECS['skip 0-2'](x.clone())\n",
        "        x_0_3 = self.VECS['skip 0-3'](x.clone())\n",
        "        x_0_4 = self.VECS['skip 0-4'](x.clone())\n",
        "        x0 = F.tanh(self.VECS['fc0'](x.clone()))\n",
        "        \n",
        "        ###################################################\n",
        "        B_x_N = x0.shape[0]\n",
        "        layer_width = x0.shape[1]//args['n_channels']\n",
        "        x0 = x0.view(( B_x_N*layer_width, args['n_channels']))\n",
        "        x1 = self.DANS['L1'](x0, args['dims'][1])\n",
        "\n",
        "        x_1_3 = self.VECS['skip 1-3'](x1.clone()) \n",
        "        x_1_4 = self.VECS['skip 1-4'](x1.clone())\n",
        "        x2 = self.VECS['fc1'](x1.clone())\n",
        "        x2 = F.tanh(x2 + x_0_2)\n",
        "\n",
        "        ##################################################\n",
        "        B_x_N = x2.shape[0]\n",
        "        layer_width = x2.shape[1]//args['n_channels']\n",
        "        x2 = x2.view(( B_x_N*layer_width, args['n_channels']))\n",
        "        x3 = self.DANS['L1'](x2, args['dims'][2])\n",
        "        \n",
        "        x_2_4 = self.VECS['skip 2-4'](x3.clone())\n",
        "        x4 = self.VECS['fc2'](x3.clone())\n",
        "        x4 = F.tanh(x4 + x_0_3 + x_1_3)\n",
        "\n",
        "        ##################################################\n",
        "        B_x_N = x4.shape[0]\n",
        "        layer_width = x4.shape[1]//args['n_channels']\n",
        "        x4 = x4.view(( B_x_N*layer_width, args['n_channels']))\n",
        "        x5 = self.DANS['L1'](x4, args['dims'][3])\n",
        "\n",
        "        x6 = self.VECS['fc3'](x5.clone())\n",
        "        x6 = F.tanh(x6 + x_0_4 + x_1_4 + x_2_4)\n",
        "\n",
        "        ##################################################\n",
        "        B_x_N = x6.shape[0]\n",
        "        layer_width = x6.shape[1]//args['n_channels']\n",
        "        x6 = x6.view(( B_x_N*layer_width, args['n_channels']))\n",
        "        x7 = self.DANS['L1'](x6, args['dims'][4])\n",
        "\n",
        "        x7 = x7.view((args['B'] , args['N']))*5.0\n",
        "        return x7\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhAnswPQMDFR"
      },
      "source": [
        "Let's take a look at the type of functions we'll be modeling "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "zFRaqC4hH9LT"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "num_tasks = 20\n",
        "samples_per_task = 5\n",
        "samples_per_function = 500\n",
        "t = np.linspace(-5, 5, samples_per_function)\n",
        "amplitude1 = np.random.uniform(.1, .9)\n",
        "amplitude2 = np.random.uniform(.1, .9)\n",
        "phase1 = np.random.uniform(0, np.pi/2)\n",
        "phase2 = np.random.uniform(0, np.pi/2)\n",
        "\n",
        "def mixture_of_sines(t, amplitude1, amplitude2, phase1, phase2):\n",
        "    \n",
        "    return ((amplitude1 * np.sin((phase1 * t) + np.random.randint(-5,5)) + amplitude2 * np.cos((phase2 * t) + np.random.randint(-5,5)))/2) \n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "y = mixture_of_sines(t, amplitude1, amplitude2, phase1, phase2)\n",
        "cur_range = max(y)-min(y)\n",
        "noisy_y = y + np.random.normal(0, cur_range*.1, size=(samples_per_function,))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "#plt.ylim(-1, 1)\n",
        "ax.set_ylim(-1, 1)\n",
        "plt.scatter(t, noisy_y, s=10, c = t, cmap='cool_r')\n",
        "plt.plot(t, y, c=\"cyan\")\n",
        "ax.set_axisbelow(True)\n",
        "ax.grid(True, axis='y', color=\"#0B262C\")\n",
        "ax.set_facecolor(\"#0C1821\")\n",
        "ax.tick_params( colors='black')\n",
        "# plt.axvline(x=-0.6, color='teal', linestyle='--')\n",
        "# plt.axvline(x=-0.2, color='teal', linestyle='--')\n",
        "# plt.axvline(x= 0.2, color='teal', linestyle='--')\n",
        "# plt.axvline(x= 0.6, color='teal', linestyle='--')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqX0GJv4jzY_"
      },
      "source": [
        "Let's sample a batch of such functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NhNIRktgj2V_"
      },
      "outputs": [],
      "source": [
        "def get_batch_of_functions(batch_size, args):\n",
        "  func_data = {}\n",
        "  func_data['batch_y'] = torch.Tensor()\n",
        "  func_data['batch_X'] = torch.Tensor()\n",
        "  func_data['y_true'] = torch.Tensor()\n",
        "\n",
        "  fps = args['func_params']\n",
        "  \n",
        "  \n",
        "  for b in range(batch_size):\n",
        "    amplitude1 = np.random.uniform(fps['amp_min'], fps['amp_max'])\n",
        "    amplitude2 = np.random.uniform(fps['amp_min'], fps['amp_max'])\n",
        "    phase1 = np.random.uniform(fps['phase_min'], fps['phase_max'])\n",
        "    phase2 = np.random.uniform(fps['phase_min'], fps['phase_max'])\n",
        "    y = mixture_of_sines(t, amplitude1, amplitude2, phase1, phase2)\n",
        "    cur_range = max(y)-min(y)\n",
        "    noisy_y = y + np.random.normal(0, cur_range*.03, size=(samples_per_function,))\n",
        "    func_data['y_true'] = torch.cat((func_data['y_true'], torch.Tensor(y).unsqueeze(0)), dim=0)\n",
        "    func_data['batch_y'] = torch.cat((func_data['batch_y'], torch.Tensor(noisy_y).unsqueeze(0)), dim=0)\n",
        "    func_data['batch_X'] = torch.cat((func_data['batch_X'], torch.Tensor(t).unsqueeze(0)), dim=0)\n",
        "    \n",
        "  return func_data\n",
        "\n",
        "#batch = get_batch_of_functions(5, args)\n",
        "\n",
        "# B,N = batch['batch_X'].shape # B = batch_size, N = num_samples per function \n",
        "# args['B'] = B\n",
        "# args['N'] = N"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp1ug93gMMW3"
      },
      "source": [
        "Let's see how we can fetch a batch of such functions and pass them through our model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'batch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\blake\\OneDrive\\Documents\\repos\\Notebooks\\HYPER_LEARNING_INCREMENTAL_REGRESSION.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/blake/OneDrive/Documents/repos/Notebooks/HYPER_LEARNING_INCREMENTAL_REGRESSION.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m NET(n_channels \u001b[39m=\u001b[39m args[\u001b[39m'\u001b[39m\u001b[39mn_channels\u001b[39m\u001b[39m'\u001b[39m], dims \u001b[39m=\u001b[39m args[\u001b[39m'\u001b[39m\u001b[39mdims\u001b[39m\u001b[39m'\u001b[39m], args\u001b[39m=\u001b[39margs)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/blake/OneDrive/Documents/repos/Notebooks/HYPER_LEARNING_INCREMENTAL_REGRESSION.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m batch[\u001b[39m'\u001b[39m\u001b[39mbatch_X\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39mbatch_X\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mview((B \u001b[39m*\u001b[39m N, \u001b[39m1\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/blake/OneDrive/Documents/repos/Notebooks/HYPER_LEARNING_INCREMENTAL_REGRESSION.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m out \u001b[39m=\u001b[39m model(batch[\u001b[39m'\u001b[39m\u001b[39mbatch_X\u001b[39m\u001b[39m'\u001b[39m], args)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/blake/OneDrive/Documents/repos/Notebooks/HYPER_LEARNING_INCREMENTAL_REGRESSION.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39mget_model_size()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'batch' is not defined"
          ]
        }
      ],
      "source": [
        "model = NET(n_channels = args['n_channels'], dims = args['dims'], args=args)\n",
        "batch['batch_X'] = batch['batch_X'].view((B * N, 1))\n",
        "out = model(batch['batch_X'], args)\n",
        "model.get_model_size()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icBJqXbRBCQf"
      },
      "source": [
        "NON-IID SAMPLING FOR CONTINUAL LEARNING\n",
        "& PLOTTING "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9zhtmU2EwpH"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "tasks = list(np.arange(num_tasks))\n",
        "\n",
        "def train_sim(batch, out):\n",
        "  filenames = []\n",
        "  time_samples = {}\n",
        "  time_samples['x'] = np.array([])\n",
        "  time_samples['y'] = np.array([])\n",
        "  y = batch['y_true'][0].detach().numpy()\n",
        "  noisy_y = batch['batch_y'][0].detach().numpy()\n",
        "  model_preds = out[0].detach().numpy()\n",
        "\n",
        "\n",
        "  step = 0\n",
        "  for task in range(num_tasks):\n",
        "    for i in range(samples_per_task):\n",
        "      cur_sample = np.random.choice(np.arange(task*int(samples_per_function/num_tasks),(task*int(samples_per_function/num_tasks))+int(samples_per_function/num_tasks)), 5)\n",
        "      time_samples['x'] = np.concatenate((time_samples['x'], t[cur_sample]))\n",
        "      time_samples['y'] = np.concatenate((time_samples['y'], noisy_y[cur_sample]))\n",
        "      fname = args['local_path']+str(step)+\".png\"\n",
        "      filenames.append(fname)\n",
        "      _ = plt.clf()\n",
        "      fig, ax = plt.subplots(figsize=(7, 4))\n",
        "      _ = plt.scatter(t, noisy_y, s=10, c = \"#353535\") # comment this line if you dont wish to plot all noisy data in the background\n",
        "      _ = plt.ylim(min(noisy_y)-.5, max(noisy_y)+0.5)\n",
        "      _ = ax.set_ylim(-1, 1)\n",
        "      _ = plt.plot(t, y, c=\"cyan\", label='y_true')\n",
        "      _ = ax.set_axisbelow(True)\n",
        "      _ = ax.grid(True, axis='y', color=\"#0B262C\")\n",
        "      _ = ax.set_facecolor(\"#0C1821\")\n",
        "      _ = ax.tick_params( colors='white')\n",
        "      _ = plt.axvline(x=-0.6, color='teal', linestyle='--')\n",
        "      _ = plt.axvline(x=-0.2, color='teal', linestyle='--')\n",
        "      _ = plt.axvline(x= 0.2, color='teal', linestyle='--')\n",
        "      _ = plt.axvline(x= 0.6, color='teal', linestyle='--')\n",
        "      _ = plt.scatter(time_samples['x'], time_samples['y'], s=10, c = np.arange(len(time_samples['x'])), cmap='cool_r')\n",
        "      _ = plt.plot(t, model_preds, c='#F5F904', linewidth=2, label='y_pred')\n",
        "      leg = plt.legend(bbox_to_anchor=(1.04, 1), loc='upper left', facecolor='black')\n",
        "      for text in leg.get_texts():\n",
        "        text.set_color(\"w\")\n",
        "      _ = plt.tight_layout()\n",
        "      _ = plt.savefig(fname, facecolor='black')\n",
        "      step += 1 \n",
        "\n",
        "  return filenames\n",
        "  \n",
        "#filenames = train_sim(batch, out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0orL0ImBMSe"
      },
      "source": [
        "LET'S MAKE A GIF\n",
        "\n",
        "Here we can see how the current training distribution evolves over time. \n",
        "The cyan color inidicates the samples currently be exposed to the model. \n",
        "The magenta color shows data that the model saw long ago, i.e. historical data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WOetyVC3b9xL"
      },
      "outputs": [],
      "source": [
        "import imageio\n",
        "from IPython.display import Image\n",
        "\n",
        "def make_gif(filenames):\n",
        "  images = []\n",
        "  for filename in filenames:\n",
        "      images.append(imageio.imread(filename))\n",
        "  mygif = imageio.mimsave(args['local_path']+'movie.gif', images, duration = 0.04)\n",
        "  Image(open(args['local_path']+'/movie.gif', 'rb').read()) \n",
        "\n",
        "#make_gif(filenames)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mG9xZTi7sGz"
      },
      "source": [
        "ALRIGHT LETS DO SOME HYPER-LEARNING\n",
        "\n",
        "First lets set some parameters and initialize our population of models "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "CeUhrYC_-KKu"
      },
      "outputs": [],
      "source": [
        "class POPULATION():\n",
        "  def __init__(self, args):\n",
        "    self.models = []\n",
        "    self.vecs_opts = []\n",
        "    self.dan_opts = []\n",
        "    self.priors = []\n",
        "    self.prior_opts = []\n",
        "    for m in range(args['population size']):\n",
        "      self.models.append(NET(n_channels = args['n_channels'], dims = args['dims'], args=args))\n",
        "      self.vecs_opts.append(torch.optim.Adam(self.models[-1].VECS.parameters(),  lr=args['vecs_lr']))\n",
        "      self.dan_opts.append(torch.optim.Adam(self.models[-1].DANS.parameters(),  lr=args['dans_lr']))\n",
        "\n",
        "      #self.priors.append(NET(n_channels = args['n_channels'], dims = args['dims']))\n",
        "    print(\"total # params: \", self.models[0].get_model_size())\n",
        "    print(\"total # DAN params: \", self.models[0].get_DAN_size())\n",
        "    print(\"total # DAN params FULL NET:\", self.models[0].get_DAN_size()*(sum(args['dims'])-1))\n",
        "    print(\"Plasticity Ratio (wrt single DAN): \", self.models[0].get_plasticity_ratio())\n",
        "    print(\"Fixed Ratio (wrt single DAN): \", round(1 - self.models[0].get_plasticity_ratio(), 2))\n",
        "    self.plasticity_ratio = self.models[0].get_plasticity_ratio()\n",
        "    self.fixed_ratio = 1 - self.models[0].get_plasticity_ratio()\n",
        "    self.hyper_losses = []\n",
        "\n",
        "    self.prior = NET(n_channels = args['n_channels'], dims = args['dims'], args=args)\n",
        "    self.prior.load_state_dict(self.models[0].state_dict())\n",
        "    self.prior_opt = torch.optim.Adam(self.prior.DANS.parameters(),  lr=args['prior_lr'])\n",
        "\n",
        "  def update_prior(self, grads, lr):\n",
        "    self.prior_opt.zero_grad()\n",
        "    for name, param in self.prior.DANS.named_parameters():\n",
        "        param.grad = grads[name]\n",
        "    self.prior_opt.step()\n",
        "    self.load_prior()\n",
        "\n",
        "  def load_prior(self):  \n",
        "    for m in range(args['population size']):\n",
        "      self.models[m].DANS.load_state_dict(self.prior.DANS.state_dict())\n",
        "      self.vecs_opts[m] = torch.optim.Adam(self.models[m].VECS.parameters(),  lr=args['vecs_lr'])\n",
        "      self.dan_opts[m] = torch.optim.Adam(self.models[m].DANS.parameters(),  lr=args['dans_lr'])\n",
        "\n",
        "  def get_reptile_loss(self, reptile, model):\n",
        "    total_loss = 0\n",
        "    for r,m in zip(reptile.DANS.parameters(), model.DANS.parameters()):\n",
        "      total_loss += F.mse_loss(m,r)\n",
        "    return total_loss\n",
        "\n",
        "  def avg_VECS(self):\n",
        "    vecs = {}\n",
        "    for idx, m in enumerate(self.models):\n",
        "        vecs[str(idx)] = m.VECS.state_dict()\n",
        "\n",
        "    for key in vecs['0']:\n",
        "      vecs['0'][key] = (vecs['0'][key] + vecs['1'][key] + vecs['2'][key])/3.\n",
        "    \n",
        "    for idx, m in enumerate(self.models):\n",
        "      m.VECS.load_state_dict(vecs['0'])\n",
        "      self.vecs_opts[idx] = torch.optim.Adam(m.VECS.parameters(),  lr=args['vecs_lr'])\n",
        "    return vecs['0'] \n",
        "    \n",
        "\n",
        "  def train(self,args):\n",
        "    batch = args['data']\n",
        "    filenames = []\n",
        "    time_samples = {}\n",
        "    time_samples['x'] = np.array([])\n",
        "    time_samples['y'] = np.array([])\n",
        "    num_tasks = args['num_tasks']\n",
        "    samples_per_task = args['samples_per_task']\n",
        "    step = 0\n",
        "    dan_grads = {}\n",
        "    prior_grads = {}\n",
        "    population_hyper_loss = 0\n",
        "   \n",
        "    for task in range(num_tasks): \n",
        "      for i in range(args['samples_per_task']):\n",
        "        \n",
        "        step +=1 \n",
        "        for m_idx, model in enumerate(self.models):\n",
        "          vecs_grads = {}\n",
        "          model.to(args['device'])\n",
        "          y_true = batch['y_true'][m_idx].detach().numpy()\n",
        "          noisy_y = batch['batch_y'][m_idx].detach().numpy()\n",
        "          vecs_opt = self.vecs_opts[m_idx]\n",
        "          if args['sampling procedure'] == 'iid':\n",
        "            cur_sample = np.random.choice(np.arange(len(t)), 5)\n",
        "          else:\n",
        "            cur_sample = np.random.choice(np.arange(task*int(samples_per_function/num_tasks),(task*int(samples_per_function/num_tasks))+int(samples_per_function/num_tasks)), 5)\n",
        "          x = torch.tensor(t[cur_sample]).unsqueeze(-1).float()\n",
        "          train_y = torch.tensor(noisy_y[cur_sample]).unsqueeze(-1).float()\n",
        "          \n",
        "          B,N = x.shape # B = number of current samples, N = input shape == 1\n",
        "          args['B'] = B\n",
        "          args['N'] = N\n",
        "          for ss in range(args['steps_per_sample']):\n",
        "            \n",
        "            vecs_opt.zero_grad()\n",
        "            out = model(x.to(args['device']), args)\n",
        "            loss =  F.mse_loss(out, train_y.to(args['device'])) \n",
        "            loss.backward()\n",
        "            if step > 1:\n",
        "              vecs_opt.step()\n",
        "          \n",
        "          # # FOR WARP GRAD\n",
        "          # for name, param in model.VECS.named_parameters():\n",
        "          #     vecs_grads[name] = param.grad.clone()\n",
        "        \n",
        "        for ss in range(50):\n",
        "            \n",
        "          dan_grads = {}\n",
        "          # # hyper_loss = 0\n",
        "          for m_idx, model in enumerate(self.models):\n",
        "            dan_opt = self.dan_opts[m_idx]\n",
        "\n",
        "            if args['algorithm'] == 'reptile':\n",
        "              reptile = NET(n_channels = args['n_channels'], dims = args['dims'], args=args)\n",
        "              reptile.load_state_dict(model.state_dict())\n",
        "              reptile_opt = torch.optim.Adam(reptile.DANS.parameters(),  lr=args['reptile_lr'])\n",
        "              reptile.to(args['device'])\n",
        "              for r_step in range(args['reptile_steps']):\n",
        "                noisy_y = batch['batch_y'][m_idx].detach().numpy()\n",
        "                cur_sample = np.random.choice(np.arange(len(t)), args['hyper_batch_size'])\n",
        "                x = torch.tensor(t[cur_sample]).unsqueeze(-1).float()\n",
        "                train_y = torch.tensor(noisy_y[cur_sample]).unsqueeze(-1).float()\n",
        "                args['B'] = args['hyper_batch_size']\n",
        "                args['N'] = 1\n",
        "                reptile_opt.zero_grad()\n",
        "                out = reptile(x.to(args['device']), args)\n",
        "                reptile_loss = F.mse_loss(out, train_y.to(args['device']))\n",
        "                if r_step == 0:\n",
        "                  if task == num_tasks-1 and i == samples_per_task-1:\n",
        "                    population_hyper_loss += (reptile_loss.item()/(args['population size']))\n",
        "                reptile_loss.backward()\n",
        "                reptile_opt.step() \n",
        "              loss = self.get_reptile_loss(reptile, model)\n",
        "            else:\n",
        "              \n",
        "              noisy_y = batch['batch_y'][m_idx].detach().numpy()\n",
        "              cur_sample = np.random.choice(np.arange(len(t)), args['hyper_batch_size'])\n",
        "              x = torch.tensor(t[cur_sample]).unsqueeze(-1).float()\n",
        "              train_y = torch.tensor(noisy_y[cur_sample]).unsqueeze(-1).float()\n",
        "              args['B'] = args['hyper_batch_size']\n",
        "              args['N'] = 1\n",
        "              model.to(args['device'])\n",
        "              \n",
        "            \n",
        "              #use this sampling procedure for memory_loss only\n",
        "              #cur_sample = np.random.choice(np.arange(0,(task*int(samples_per_function/num_tasks))+int(samples_per_function/num_tasks)), args['hyper_batch_size'])\n",
        "            \n",
        "              \n",
        "              out = model(x.to(args['device']), args)\n",
        "\n",
        "              loss = F.mse_loss(out, train_y.to(args['device']))\n",
        "              if task == num_tasks-1 and i == samples_per_task-1:\n",
        "                population_hyper_loss += loss.item()/(args['population size'])\n",
        "            dan_opt.zero_grad()\n",
        "            vecs_opt.zero_grad()\n",
        "            loss.backward()\n",
        "          \n",
        "            \n",
        "            if m_idx == 0:\n",
        "                for name, param in model.DANS.named_parameters():\n",
        "                    dan_grads[name] = param.grad.clone().detach()  \n",
        "                # if task == 0 and i == 0:\n",
        "                #   for name, param in model.VECS.named_parameters():\n",
        "                #       prior_grads[name] = param.grad.clone().detach()  \n",
        "                # else:\n",
        "                #   for name, param in model.VECS.named_parameters():\n",
        "                #     prior_grads[name] += param.grad.clone().detach()             \n",
        "            else:\n",
        "                for name, param in model.DANS.named_parameters():\n",
        "                    dan_grads[name] += param.grad.clone().detach()\n",
        "                # for name, param in model.VECS.named_parameters():\n",
        "                #     prior_grads[name] += param.grad.clone().detach()\n",
        "            #dan_opt.step()       \n",
        "            \n",
        "            # # FOR WARP-GRAD\n",
        "            # vecs_opt.zero_grad()\n",
        "            # for name, param in model.VECS.named_parameters():\n",
        "            #       param.grad = vecs_grads[name]\n",
        "            # if step > 0:\n",
        "            #   vecs_opt.step()  \n",
        "          # #NOW AVERAGE THE DAN GRADS, AND UPDATE THE DANS IN ALL MODELS. \n",
        "          for m_idx, model in enumerate(self.models):\n",
        "              self.dan_opts[m_idx].zero_grad()\n",
        "              for name, param in self.models[m_idx].DANS.named_parameters():\n",
        "                  param.grad = dan_grads[name]/((args['population size']))\n",
        "              self.dan_opts[m_idx].step()\n",
        "\n",
        "    \n",
        "    # self.prior_opt.zero_grad()\n",
        "    # for name, param in self.prior.DANS.named_parameters():\n",
        "    #     param.grad = prior_grads[name]/((args['population size'])*args['num_tasks']*args['samples_per_task'])\n",
        "    # self.prior_opt.step()\n",
        "    self.hyper_losses.append(population_hyper_loss)\n",
        "\n",
        "    #avg_vecs = self.avg_VECS()\n",
        "   \n",
        "    \n",
        "    for m_idx, m in enumerate(self.models):\n",
        "      self.vecs_opts[m_idx] = m.reset_VECS(args['vecs_lr'])  \n",
        "      \n",
        "    #self.update_prior(dan_grads, args['prior_lr'])\n",
        "    \n",
        "    return self.hyper_losses\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "  def test(self,args):   \n",
        "    batch = args['data']\n",
        "    filenames = []\n",
        "    time_samples = {}\n",
        "    time_samples['x'] = np.array([])\n",
        "    time_samples['y'] = np.array([])\n",
        "    num_tasks = args['num_tasks']\n",
        "    samples_per_task = args['samples_per_task']\n",
        "    y_true = batch['y_true'][0].detach().numpy()\n",
        "    noisy_y = batch['batch_y'][0].detach().numpy()\n",
        "    \n",
        "      \n",
        "    step = 0\n",
        "    for task in range(num_tasks):\n",
        "      \n",
        "      for i in range(args['samples_per_task']):\n",
        "        \n",
        "        population_training_loss = 0\n",
        "        for m_idx, model in enumerate([self.models[0]]):\n",
        "          model.to(args['device'])\n",
        "          noisy_y = batch['batch_y'][m_idx].detach().numpy()\n",
        "          vecs_opt = self.vecs_opts[m_idx]\n",
        "         \n",
        "          if args['sampling procedure'] == 'iid':\n",
        "            cur_sample = np.random.choice(np.arange(len(t)), 5)\n",
        "          else:\n",
        "            cur_sample = np.random.choice(np.arange(task*int(samples_per_function/num_tasks),(task*int(samples_per_function/num_tasks))+int(samples_per_function/num_tasks)), 5)\n",
        "          x = torch.tensor(t[cur_sample]).unsqueeze(-1).float()\n",
        "          y = torch.tensor(noisy_y[cur_sample]).unsqueeze(-1).float()\n",
        "          \n",
        "          \n",
        "          B,N = x.shape # B = number of current samples, N = input shape == 1\n",
        "          args['B'] = B\n",
        "          args['N'] = N\n",
        "          for ss in range(args['steps_per_sample']):\n",
        "            vecs_opt.zero_grad()\n",
        "            out = model(x.to(args['device']), args)\n",
        "            loss = F.mse_loss(out, y.to(args['device']))\n",
        "            population_training_loss += loss.item()/args['population size']\n",
        "            loss.backward()\n",
        "\n",
        "            if step > 0:\n",
        "              vecs_opt.step()\n",
        "           \n",
        "          all_x = torch.tensor(t).unsqueeze(-1).float()\n",
        "          args['B'] = all_x.shape[0]\n",
        "          model_preds = model(all_x.to(args['device']), args).cpu().detach().numpy() #get preds over whole function\n",
        "\n",
        "          time_samples['x'] = np.concatenate((time_samples['x'], torch.flatten(x)))\n",
        "          time_samples['y'] = np.concatenate((time_samples['y'], torch.flatten(y)))\n",
        "          fname = args['local_path']+str(step)+\".png\"\n",
        "          filenames.append(fname)\n",
        "          _ = plt.clf()\n",
        "          fig, ax = plt.subplots(figsize=(7, 4))\n",
        "          #_ = plt.scatter(t, noisy_y, s=10, c = \"#353535\") # comment this line if you dont wish to plot all noisy data in the background\n",
        "          _ = ax.set_ylim(-1, 1)\n",
        "          _ = plt.plot(t, y_true, c=\"cyan\", label='y_true')\n",
        "          _ = ax.set_axisbelow(True)\n",
        "          _ = ax.grid(True, axis='y', color=\"#0B262C\")\n",
        "          _ = ax.set_facecolor(\"#0C1821\")\n",
        "          _ = ax.tick_params( colors='white')\n",
        "          # _ = plt.axvline(x=-0.6, color='teal', linestyle='--')\n",
        "          # _ = plt.axvline(x=-0.2, color='teal', linestyle='--')\n",
        "          # _ = plt.axvline(x= 0.2, color='teal', linestyle='--')\n",
        "          # _ = plt.axvline(x= 0.6, color='teal', linestyle='--')\n",
        "          _ = plt.scatter(time_samples['x'], time_samples['y'], s=10, c = np.arange(len(time_samples['x'])), cmap='cool_r')\n",
        "          _ = plt.plot(t, model_preds, c='#F5F904', linewidth=2, label='y_pred')\n",
        "          leg = plt.legend(bbox_to_anchor=(1.04, 1), loc='upper left', facecolor='black')\n",
        "          for text in leg.get_texts():\n",
        "            text.set_color(\"w\")\n",
        "          _ = plt.tight_layout()\n",
        "          _ = plt.savefig(fname, facecolor='black')\n",
        "\n",
        "          \n",
        "          step += 1 \n",
        "\n",
        "    for m_idx, m in enumerate(self.models):\n",
        "      self.vecs_opts[m_idx] = m.reset_VECS(args['vecs_lr']) \n",
        "    #self.load_prior()\n",
        "\n",
        "\n",
        "    make_gif(filenames)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "0Z8NuBMuz0j1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "THESE WORK DECENTLY...\n",
        "\n",
        "args['population size'] = 5\n",
        "args['models'] = []\n",
        "args['algorithm'] = 'hyper-learning' # ['warp grad', 'hyper-learning', 'reptile']\n",
        "args['vecs_opts'] = []\n",
        "args['dan_opts'] = []\n",
        "args['outer_epochs'] = 200\n",
        "args['device'] = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "args['vecs_lr'] = .01\n",
        "args['dans_lr'] = .01\n",
        "args['reptile_lr'] = .001\n",
        "args['reptile_steps'] = 100\n",
        "args['hyper_batch_size'] = 20\n",
        "args['num_tasks'] = 2\n",
        "args['samples_per_task'] = 15\n",
        "args['samples_per_tasks'] = [5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5] #[50,50,45,45,40,40,35,35,30,30,25,25,20,20,15,15,10,10,5,5]\n",
        "args['n_channels'] = 25\n",
        "args['dan_width'] = 25\n",
        "args['dims'] = [1, 10, 10, 10, 1]\n",
        "\"\"\"\n",
        "\n",
        "args['population size'] = 3\n",
        "args['models'] = []\n",
        "args['algorithm'] = 'hyper-learning' # ['warp grad', 'hyper-learning', 'reptile', 'full net iid']\n",
        "args['vecs_opts'] = []\n",
        "args['dan_opts'] = []\n",
        "args['outer_epochs'] = 200\n",
        "args['device'] = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "args['vecs_lr'] = .01\n",
        "args['dans_lr'] = .01\n",
        "args['prior_lr'] = .01\n",
        "args['reptile_lr'] = .01\n",
        "args['reptile_steps'] = 10\n",
        "args['hyper_batch_size'] = 20\n",
        "args['num_tasks'] = 5\n",
        "args['sampling procedure'] = 'non-iid task incremental' # ['iid', 'non-iid task incremental',]\n",
        "args['samples_per_task'] = 10\n",
        "args['steps_per_sample'] = 1\n",
        "args['samples_per_tasks'] = [5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5] #[50,50,45,45,40,40,35,35,30,30,25,25,20,20,15,15,10,10,5,5]\n",
        "args['n_channels'] = 40\n",
        "args['dan_width'] = 40\n",
        "args['dims'] = [1, 10, 10, 10, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "4QMF3_OC_akO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total # params:  27004\n",
            "total # DAN params:  10004\n",
            "total # DAN params FULL NET: 310124\n",
            "Plasticity Ratio (wrt single DAN):  0.63\n",
            "Fixed Ratio (wrt single DAN):  0.37\n"
          ]
        }
      ],
      "source": [
        "args['population'] = POPULATION(args)\n",
        "args['hyper_epoch'] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4QvWV56GJYt"
      },
      "source": [
        "Now we want to start training our population and visualizing how its going along the way "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "h6kL5urcr-cz"
      },
      "outputs": [],
      "source": [
        "def moving_average(x, w):\n",
        "    return np.convolve(x, np.ones(w), 'valid') / w\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_func_params(args, mode):\n",
        "    args['func_params'] = {}\n",
        "    if mode == \"train\":\n",
        "        args['func_params']['amp_min'] = .1\n",
        "        args['func_params']['amp_max'] = .9\n",
        "        args['func_params']['phase_min'] = np.pi/6\n",
        "        args['func_params']['phase_max'] = np.pi\n",
        "    else:\n",
        "        args['func_params']['amp_min'] = .1\n",
        "        args['func_params']['amp_max'] = .9\n",
        "        args['func_params']['phase_min'] = np.pi/6\n",
        "        args['func_params']['phase_max'] = np.pi/2\n",
        "    return args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "f4zzW8APGJBn"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\blake\\OneDrive\\Documents\\repos\\Notebooks\\HYPER_LEARNING_INCREMENTAL_REGRESSION.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/blake/OneDrive/Documents/repos/Notebooks/HYPER_LEARNING_INCREMENTAL_REGRESSION.ipynb#X31sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m args \u001b[39m=\u001b[39m set_func_params(args, \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/blake/OneDrive/Documents/repos/Notebooks/HYPER_LEARNING_INCREMENTAL_REGRESSION.ipynb#X31sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m args[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m get_batch_of_functions(args[\u001b[39m'\u001b[39m\u001b[39mpopulation size\u001b[39m\u001b[39m'\u001b[39m], args)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/blake/OneDrive/Documents/repos/Notebooks/HYPER_LEARNING_INCREMENTAL_REGRESSION.ipynb#X31sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m hyper_losses \u001b[39m=\u001b[39m args[\u001b[39m'\u001b[39;49m\u001b[39mpopulation\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mtrain(args)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/blake/OneDrive/Documents/repos/Notebooks/HYPER_LEARNING_INCREMENTAL_REGRESSION.ipynb#X31sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m window \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/blake/OneDrive/Documents/repos/Notebooks/HYPER_LEARNING_INCREMENTAL_REGRESSION.ipynb#X31sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m plt\u001b[39m.\u001b[39mclf()\n",
            "\u001b[1;32mc:\\Users\\blake\\OneDrive\\Documents\\repos\\Notebooks\\HYPER_LEARNING_INCREMENTAL_REGRESSION.ipynb Cell 23\u001b[0m in \u001b[0;36mPOPULATION.train\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/blake/OneDrive/Documents/repos/Notebooks/HYPER_LEARNING_INCREMENTAL_REGRESSION.ipynb#X31sZmlsZQ%3D%3D?line=153'>154</a>\u001b[0m dan_opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/blake/OneDrive/Documents/repos/Notebooks/HYPER_LEARNING_INCREMENTAL_REGRESSION.ipynb#X31sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m vecs_opt\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/blake/OneDrive/Documents/repos/Notebooks/HYPER_LEARNING_INCREMENTAL_REGRESSION.ipynb#X31sZmlsZQ%3D%3D?line=155'>156</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/blake/OneDrive/Documents/repos/Notebooks/HYPER_LEARNING_INCREMENTAL_REGRESSION.ipynb#X31sZmlsZQ%3D%3D?line=158'>159</a>\u001b[0m \u001b[39mif\u001b[39;00m m_idx \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/blake/OneDrive/Documents/repos/Notebooks/HYPER_LEARNING_INCREMENTAL_REGRESSION.ipynb#X31sZmlsZQ%3D%3D?line=159'>160</a>\u001b[0m     \u001b[39mfor\u001b[39;00m name, param \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mDANS\u001b[39m.\u001b[39mnamed_parameters():\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    487\u001b[0m     )\n\u001b[1;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    490\u001b[0m )\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torch\\autograd\\__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "torch.cuda.empty_cache()\n",
        "hyper_losses = []\n",
        "\n",
        "for epoch in range(args['outer_epochs']):\n",
        "  \"\"\"  args['data'] contains {'y_true', 'batch_y', 'batch_y'}\"\"\"\n",
        "  args = set_func_params(args, \"train\")\n",
        "  args['data'] = get_batch_of_functions(args['population size'], args)\n",
        "  \n",
        "  hyper_losses = args['population'].train(args)\n",
        "\n",
        "  window = 5\n",
        "  plt.clf()\n",
        "  fig, ax = plt.subplots(figsize=(7, 4))\n",
        "  x = np.arange(len(hyper_losses))\n",
        "  _ = ax.set_axisbelow(True)\n",
        "  _ = ax.grid(True, axis='y', color=\"#0B262C\")\n",
        "  _ = ax.set_facecolor(\"#0C1821\")\n",
        "  _ = ax.set_ylim(0, max(hyper_losses)*1.1)\n",
        "  _ = ax.tick_params( colors='white')\n",
        "  plt.scatter(x[:], hyper_losses[:], s=10, c = hyper_losses[:], cmap='cool')\n",
        "  if len(hyper_losses) > window+1:\n",
        "    mv_avg = moving_average( hyper_losses, window)\n",
        "    plt.plot(x[window-1:],mv_avg[:], c=\"yellow\")\n",
        "    _ = ax.set_ylim(0, .2)\n",
        "  _ = plt.savefig(args['local_path']+\"Hyper-Loss.png\", facecolor='black')\n",
        "\n",
        "\n",
        "  args['hyper_epoch'] += 1\n",
        "  if epoch % 5 == 0:\n",
        "    args = set_func_params(args, \"test\")\n",
        "    args['data'] = get_batch_of_functions(1, args)\n",
        "    args['population'].test(args)\n",
        "\n",
        "    model_name = \"HLIR_model.pt\"\n",
        "    path = args['local_path']+model_name\n",
        "    torch.save({\n",
        "                'epoch': args['hyper_epoch'],\n",
        "                'model_state_dict': args['population'].models[0].state_dict(),\n",
        "                'optimizer_state_dict': args['population'].dan_opts[0].state_dict(),\n",
        "                'hyper_losses': hyper_losses\n",
        "               }, path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3r3fWd8a5el"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mFailed to start the Kernel. \n",
            "\u001b[1;31mUnable to start Kernel 'Python 3.9.13' due to connection timeout. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "plt.clf()\n",
        "fig, ax = plt.subplots(figsize=(7, 4))\n",
        "x = np.arange(len(hyper_losses))\n",
        "window = 20\n",
        "_ = ax.set_axisbelow(True)\n",
        "_ = ax.grid(True, axis='y', color=\"#0B262C\")\n",
        "_ = ax.set_facecolor(\"#0C1821\")\n",
        "_ = ax.tick_params( colors='white')\n",
        "# plt.yscale(\"log\") \n",
        "# _ = ax.set_yticks((0., .00625, .0125, .025, .05, .1, .2, .4))\n",
        "plt.scatter(x[115:], hyper_losses[115:], s=10, c = hyper_losses[115:], cmap='cool')\n",
        "if len(hyper_losses) > window+1:\n",
        "  mv_avg = moving_average( hyper_losses, window)\n",
        "  plt.plot(x[window-1+15:],mv_avg[15:], c=\"yellow\")\n",
        "_ = plt.savefig(args['local_path']+\"Hyper-Loss.png\", facecolor='black')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "ylWjwohItwHb"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "args = set_func_params(args, \"test\")\n",
        "args['samples_per_task'] = 70\n",
        "args['data'] = get_batch_of_functions(1, args)\n",
        "args['population'].test(args)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "0d630916f0ed7390d4ba868d423f34778b448983597e37c785441e8e08756095"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
